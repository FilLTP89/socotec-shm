{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9609fae0",
   "metadata": {},
   "source": [
    "## Analyse fréquentielle des séries de temps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec360d85",
   "metadata": {},
   "source": [
    "### Chargement des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b602ee0-5679-4798-a2be-32b189b504fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting root folder \n",
    "%matplotlib widget\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "parent_dir = os.path.abspath('..')\n",
    "\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "## Imports \n",
    "\n",
    "# Native imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import pywt\n",
    "from stockwell import st\n",
    "\n",
    "\n",
    "import subprocess\n",
    "from shutil import copy, move\n",
    "import json\n",
    "import csv\n",
    "import openpyxl\n",
    "\n",
    "# Signal processing packages\n",
    "from scipy.signal import detrend\n",
    "from scipy.fft import fft, fftfreq, fftshift\n",
    "# Peak detection\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.signal.windows import get_window\n",
    "#!pip install PeakUtils\n",
    "\n",
    "# REGEX\n",
    "import re\n",
    "\n",
    "# Time manipulation packages\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "# Visualizing progress\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c27889d2-c341-44c9-adf0-e87288a76ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, Javascript, display\n",
    "\n",
    "def initialize():\n",
    "    display(HTML(\n",
    "        '''\n",
    "            <script>\n",
    "                code_show = false;\n",
    "                function restart_run_all(){\n",
    "                    IPython.notebook.kernel.restart();\n",
    "                    setTimeout(function(){\n",
    "                        IPython.notebook.execute_all_cells();\n",
    "                    }, 10000)\n",
    "                }\n",
    "                function code_toggle() {\n",
    "                    if (code_show) {\n",
    "                        $('div.input').hide(200);\n",
    "                    } else {\n",
    "                        $('div.input').show(200);\n",
    "                    }\n",
    "                    code_show = !code_show\n",
    "                }\n",
    "                restart_run_all();\n",
    "            </script>\n",
    "        '''\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3c91bf5-d534-40fb-9e66-a0677362b871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SIGNAL PROCESSING ANALYSIS TOOLS\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# FFT analysis tools\n",
    "# =============================================================================\n",
    "\n",
    "def next_power_of_2(x):\n",
    "    return 1 if x == 0 else math.ceil(math.log2(x))\n",
    "\n",
    "def df_FFT(y, Fs, win = 'boxcar'):\n",
    "    '''\n",
    "    Creates a dataframe with frequency bins and amplitudes of a given signal with windowing.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y : np.array\n",
    "        Sample points.\n",
    "    Fs : float\n",
    "        Sample frequency.\n",
    "    win : string, optional\n",
    "        Window used. The default is 'hann'.\n",
    "        Works with the following windows:\n",
    "            boxcar\n",
    "            triang\n",
    "            blackman\n",
    "            hamming\n",
    "            hann\n",
    "            bartlett\n",
    "            flattop\n",
    "            parzen\n",
    "            bohman\n",
    "            blackmanharris\n",
    "            nuttall\n",
    "            barthann\n",
    "            cosine\n",
    "            exponential\n",
    "            tukey\n",
    "            taylor\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_ywf : pd.DataFrame\n",
    "        Table with \n",
    "            xf : frequency bins\n",
    "            yf : Acceleration RMS.\n",
    "\n",
    "    '''\n",
    "    # Setting constants\n",
    "    dt = 1 / Fs                         # Sample time\n",
    "    N = len(y)                          # Number of samples\n",
    "    \n",
    "    # For computational efficiency, use nfft instead of N (algorithm is efficient in powers of 2)\n",
    "    nfft = 2**next_power_of_2(N+1)    # Number of frequency points\n",
    "    \n",
    "    # Getting window\n",
    "    w = get_window(win, N)\n",
    "    \n",
    "    # Performing fft\n",
    "    xf = fftfreq(nfft, d = dt)\n",
    "    yf_c = fft(y*w, n = nfft)\n",
    "    \n",
    "    yf = [0]*len(yf_c)\n",
    "    \n",
    "    yf[0]  = np.abs(yf_c[0])**2  \n",
    "    yf[1:] = np.abs(yf_c[1:])**2\n",
    "    \n",
    "    # Creating export dataframe\n",
    "    df_ywf = pd.DataFrame({\n",
    "        'xf' : xf,\n",
    "        'yf' : yf\n",
    "        })\n",
    "    \n",
    "    return df_ywf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe55c84",
   "metadata": {},
   "source": [
    "### Traduction en fichier .txt les fichiers brutes .dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dbcf6ea-a8a9-4feb-b90e-4558955920f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.abspath(\"\")\n",
    "pathRawData =  os.path.join(os.path.abspath(\"\"),r'..',r'data',r'rawdat_data')\n",
    "pathData = os.path.join(os.path.abspath(\"\"),r'..',r'data',r'rawtxt_data')\n",
    "pathTraitement = 'Traitement'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13b82649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # retrieve all .dat file in current directory \n",
    "# files = [file for file in os.listdir(pathRawData) if file.endswith(\".dat\")]\n",
    "\n",
    "# for file in files: \n",
    "\n",
    "#     if file+'.txt' not in os.listdir(pathData):\n",
    "#         print(f'Processing {file}')\n",
    "\n",
    "#         if not os.path.exists(pathTraitement):\n",
    "#             os.mkdir(pathTraitement)\n",
    "\n",
    "#         copy(\n",
    "#             os.path.join(pathRawData,file), \n",
    "#             os.path.join(pathTraitement,'result.dat')\n",
    "#         )\n",
    "\n",
    "#         os.startfile('decodetest.bat')\n",
    "\n",
    "#         time.sleep(2)\n",
    "\n",
    "#         os.system(\"taskkill /im DecodeBin2Ascii.exe /f\")\n",
    "\n",
    "#         os.rename(\n",
    "#             os.path.join(pathTraitement, 'result.dat.txt'),\n",
    "#             os.path.join(pathTraitement, file+'.txt')\n",
    "#         )\n",
    "\n",
    "#         move(\n",
    "#             os.path.join(pathTraitement,file+'.txt'),\n",
    "#             pathData\n",
    "#         )\n",
    "\n",
    "#         os.remove(os.path.join(pathTraitement,'result.dat'))\n",
    "        \n",
    "# print('Tous les fichiers sont à jour!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07c672dd-884c-4793-843f-4664a7c8ac56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# READING OF A .DAT.TXT FILE\n",
    "# =============================================================================\n",
    "\n",
    "def read_GANTNER_dat_txt(fileName, export_dict = False):\n",
    "    '''\n",
    "    \n",
    "    Lecture d'un fichier .dat.txt type VDV décodé sous la forme d'un dictionnaire contenant toutes les informations et dataFrame pandas.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fileName : str\n",
    "        la localisation du fichier dat.txt à lire\n",
    "    export_dict : bool, optional\n",
    "        Variable permettant d'exporter ou non le dictionnaire d'information préliminaire du fichier. The default is False.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_file : pd.DataFrame\n",
    "        dataframe des données du dat.txt\n",
    "    dict_file : dict\n",
    "        dictionnaire des informations du dat.txt\n",
    "        \n",
    "        \n",
    "    Examples\n",
    "    -------\n",
    "    \n",
    "\n",
    "    '''\n",
    "    import codecs\n",
    "    dict_file = {}\n",
    "    with codecs.open(fileName, 'r', 'windows-1252') as my_file: #'utf8', \n",
    "        for (n,line) in enumerate(my_file):\n",
    "            if line.encode('utf-8').strip():\n",
    "                if re.search(r'[*]+', line):\n",
    "                    break\n",
    "                else:\n",
    "                    info_match = re.findall(r'([A-Za-z]*): ([^\\/\\n]*)', line) \n",
    "            \n",
    "                    for key,value in info_match:\n",
    "                        if key in dict_file:\n",
    "                            dict_file[key].append(value.replace(\" \", \"\"))\n",
    "                        else:\n",
    "                            dict_file.update({key: [value.replace(\" \", \"\")]})\n",
    "            \n",
    "        df_file = pd.read_csv(fileName,\n",
    "                              skiprows = range(n+1),\n",
    "                              sep = '\\t',\n",
    "                              usecols = list(range(1,len(dict_file['Name'])+1)),\n",
    "                              names = dict_file['Name'],\n",
    "                              encoding='unicode_escape')        \n",
    "        df_file = (df_file)\n",
    "        \n",
    "#     with open(fileName, 'r', encoding= 'windows-1252') as f:\n",
    "                \n",
    "#         # Stockage des infos préliminaires dans un dictionnaire\n",
    "#         dict_file = {}\n",
    "\n",
    "#         line = f.readline()\n",
    "        \n",
    "#         # Match correspond à la ligne séparatrice entre les infos prélim et les données\n",
    "#         match = re.search(r'[*]+', line) # corresponde à ***************************************\n",
    "        \n",
    "#         # Nombre de ligne à sauter pour accéder aux données\n",
    "#         n = 1\n",
    "        \n",
    "#         # Boucle pour extraire les données préliminaires\n",
    "#         while match is None:\n",
    "            \n",
    "#             # Match entre key et value des infos prélim \n",
    "#             # (Seul problème avec le StartTime, à modifier)\n",
    "#             info_match = re.findall(r'([A-Za-z]*): ([^\\/\\n]*)', line) \n",
    "            \n",
    "#             for key,value in info_match:\n",
    "#                 if key in dict_file:\n",
    "#                     dict_file[key].append(value)\n",
    "#                 else:\n",
    "#                     dict_file.update({key: [value]})\n",
    "#             line = f.readline()\n",
    "#             match = re.search(r'[*]+', line)\n",
    "#             n += 1\n",
    "        \n",
    "#         set_trace()\n",
    "#         df_file = (\n",
    "#             pd.read_csv(fileName,\n",
    "#                         skiprows = range(n), \n",
    "#                         sep = '\\t',\n",
    "#                         usecols = list(range(1,len(dict_file['Name'])+1)),\n",
    "#                         names = dict_file['Name'],\n",
    "#                         encoding='unicode_escape')\n",
    "#         )\n",
    "\n",
    "    if export_dict == True:\n",
    "        return df_file, dict_file\n",
    "    else:\n",
    "        return df_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e914076-e58d-4f4e-b6ac-6d7fe94cd3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_GANTNER_dat_txt(data_path, file):\n",
    "    \n",
    "    # Extracting date and time\n",
    "    date, heure = re.findall(r'(\\d{4}-\\d{2}-\\d{2})_(\\d{2}-\\d{2}-\\d{2})', file)[0]\n",
    "    \n",
    "    file_path = os.path.join(data_path,file)\n",
    "    \n",
    "    # File as df\n",
    "    df_jour = read_GANTNER_dat_txt(file_path)\n",
    "    \n",
    "    # Creating time indexes\n",
    "    df_jour.loc[:,'Date_Heure'] = pd.date_range(\n",
    "        start = pd.to_datetime(\n",
    "            f'{date} {heure}',\n",
    "            format = '%Y-%m-%d %H-%M-%S'),\n",
    "        freq ='0.01S', \n",
    "        periods = len(df_jour)\n",
    "        )\n",
    "    \n",
    "    # Reseting indexes\n",
    "    df_jour.index = df_jour['Date_Heure']\n",
    "    try:\n",
    "        df_jour = df_jour[['accelero1(x)','accelero2(y)','PT100']].rename(\n",
    "            columns = {'accelero1(x)':'Capteur_1','accelero2(y)':'Capteur_2',\n",
    "                       'PT100' : 'Temperature'})\n",
    "        df_jour = df_jour.apply(lambda x: x.str.replace(',','.')).astype(float)\n",
    "        return df_jour\n",
    "    except:\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6d3737",
   "metadata": {},
   "source": [
    "### Création de la base de données des fréquences basées sur les accélérations des capteurs 1 et 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b376e7-3ff3-4746-8ec0-96a58cdbd63c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2890db6f987a47eba62dbf455e04e6b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/957 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Code qui génère Base de données_Fréquences_Capteurs_1_&_2\n",
    "\n",
    "onlyTXT = [f for f in listdir(pathData) if f.endswith('.txt')]\n",
    "\n",
    "# Creation du fichier vierge\n",
    "df_capt_brut = pd.DataFrame(columns = ['Date_Heure','Temperature','Frequence_1_1','Frequence_2_1','Frequence_3_1','Frequence_1_2','Frequence_2_2','Frequence_3_2'])\n",
    "\n",
    "Date_Heure = len(onlyTXT)*[0]\n",
    "\n",
    "for i, TXT in enumerate(onlyTXT):\n",
    "    date, heure = re.findall(r'(\\d{4}-\\d{2}-\\d{2})_(\\d{2}-\\d{2}-\\d{2})', TXT)[0]\n",
    "    Date_Heure[i] = f'{date} {heure}'\n",
    "\n",
    "c = len(onlyTXT)\n",
    "\n",
    "fmin =  0.0  # Hz\n",
    "fmax = 5.0  # Hz\n",
    "fs = 100 # Hz - Sampling frequency\n",
    "# \n",
    "\n",
    "# stock = st.st(w, fmin_samples, fmax_samples)\n",
    "\n",
    "\n",
    "# Ajout des valeurs de fréquence au fichier\n",
    "for i, TXT in enumerate(tqdm(onlyTXT)):\n",
    "    \n",
    "    # Création du dataframe du jour et de l'heure\n",
    "    date, heure = re.findall(r'(\\d{4}-\\d{2}-\\d{2})_(\\d{2}-\\d{2}-\\d{2})', TXT)[0]\n",
    "    df_jour = prep_GANTNER_dat_txt(pathData, TXT)\n",
    "    if df_jour.empty:\n",
    "        pass\n",
    "    else:\n",
    "        dtm = (df_jour.index[1]-df_jour.index[0]).total_seconds()\n",
    "        vtm = np.array((df_jour.index-df_jour.index[0]).total_seconds())\n",
    "        df_jour.loc[:,[\"Capteur_1\",\"Capteur_2\"]] = df_jour.loc[:,[\"Capteur_1\",\"Capteur_2\"]].apply(detrend)\n",
    "        df = 1./dtm  # sampling step in frequency domain (Hz)\n",
    "        fmin_samples = int(fmin/df)\n",
    "        fmax_samples = int(fmax/df)\n",
    "        stock = st.st(df_jour[\"Capteur_1\"].values, fmin_samples, fmax_samples)\n",
    "        \n",
    "        extent = (vtm[0], vtm[-1], fmin, fmax)\n",
    "        fig, ax = plt.subplots(2, 1, sharex=True)\n",
    "        ax[0].plot(vtm, df_jour[\"Capteur_1\"].values)\n",
    "        ax[0].set(ylabel='amplitude')\n",
    "        ax[1].imshow(np.abs(stock), origin='lower', extent=extent)\n",
    "        ax[1].yscale('log')\n",
    "        ax[1].axis('tight')\n",
    "        ax[1].set(xlabel='time (s)', ylabel='frequency (Hz)')\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29415168-7751-41a3-b37c-451ffe7feac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#             y1 = df_jour.Capteur_1.to_list()\n",
    "#             y2 = df_jour.Capteur_2.to_list()\n",
    "\n",
    "#             # Performing a FFT on both sets, merging and taking positive frequency bins\n",
    "#             df_ywf1 = df_FFT(y1, Fs, win = 'boxcar').rename({'yf' : 'Y1'}, axis = 'columns')\n",
    "#             df_ywf2 = df_FFT(y2, Fs, win = 'boxcar').rename({'yf' : 'Y2'}, axis = 'columns')\n",
    "#             df_ywf = df_ywf1.merge(df_ywf2, on = 'xf')\n",
    "#             df_ywf_1 = df_ywf[(df_ywf.xf >= 0.5) & ((df_ywf.xf <= 0.7))]\n",
    "#             df_ywf_2 = df_ywf[(df_ywf.xf >= 1.0) & ((df_ywf.xf <= 1.6))]\n",
    "#             df_ywf_3 = df_ywf[(df_ywf.xf >= 2.0) & ((df_ywf.xf <= 2.9))]\n",
    "#             idx = pd.to_datetime(f'{date} {heure}', format = \"%Y-%m-%d %H-%M-%S\")\n",
    "\n",
    "#         # Capteur 1\n",
    "\n",
    "#         # Ajout des valeurs de Fréquence_1_1\n",
    "#         if((df_ywf_1.Y1.iloc[0] == 0)):\n",
    "#             df_capt_brut.loc[idx, 'Date_Heure'] = idx\n",
    "#             df_capt_brut.loc[idx,'Temperature'] = np.nan\n",
    "#             df_capt_brut.loc[idx, 'Frequence_1_1'] = np.nan\n",
    "#         else:\n",
    "#             min_prominence = 1000\n",
    "#             peaks, peak_dict = find_peaks(df_ywf_1.Y1, prominence=(None, min_prominence), distance=100)\n",
    "#             peaks_max_1 = df_ywf_1.xf.to_numpy()[peaks[np.argsort(peak_dict['prominences'])[::-1]]][:1]\n",
    "\n",
    "#             if((peaks_max_1.size==0)):\n",
    "#                 df_capt_brut.loc[idx, 'Date_Heure'] = idx\n",
    "#                 df_capt_brut.loc[idx,'Temperature'] = df_jour.Temperature.mean()\n",
    "#                 df_capt_brut.loc[idx, 'Frequence_1_1'] = np.nan\n",
    "#             if((peaks_max_1.size==1)) :\n",
    "#                 df_capt_brut.loc[idx, 'Date_Heure'] = idx\n",
    "#                 df_capt_brut.loc[idx,'Temperature'] = df_jour.Temperature.mean()\n",
    "#                 df_capt_brut.loc[idx, 'Frequence_1_1'] = peaks_max_1[0]\n",
    "#         # Ajout des valeurs de Fréquence_2_1\n",
    "#         if((df_ywf_2.Y1.iloc[0] == 0)):\n",
    "#             df_capt_brut.loc[idx, 'Date_Heure'] = idx\n",
    "#             df_capt_brut.loc[idx,'Temperature'] = np.nan\n",
    "#             df_capt_brut.loc[idx, 'Frequence_2_1'] = np.nan\n",
    "#         else:\n",
    "#             min_prominence = 1000\n",
    "#             peaks, peak_dict = find_peaks(df_ywf_2.Y1, prominence=(None, min_prominence), distance=100)\n",
    "#             peaks_max_1 = df_ywf_2.xf.to_numpy()[peaks[np.argsort(peak_dict['prominences'])[::-1]]][:1]\n",
    "\n",
    "#             if((peaks_max_1.size==0)):\n",
    "#                 df_capt_brut.loc[idx, 'Date_Heure'] = idx\n",
    "#                 df_capt_brut.loc[idx,'Temperature'] = df_jour.Temperature.mean()\n",
    "#                 df_capt_brut.loc[idx, 'Frequence_2_1'] = np.nan\n",
    "#             if((peaks_max_1.size==1)) :\n",
    "#                 df_capt_brut.loc[idx, 'Date_Heure'] = idx\n",
    "#                 df_capt_brut.loc[idx,'Temperature'] = df_jour.Temperature.mean()\n",
    "#                 df_capt_brut.loc[idx, 'Frequence_2_1'] = peaks_max_1[0]\n",
    "#         # Ajout des valeurs de Fréquence_3_1\n",
    "#         if((df_ywf_3.Y1.iloc[0] == 0)):\n",
    "#             df_capt_brut.loc[idx, 'Date_Heure'] = idx\n",
    "#             df_capt_brut.loc[idx,'Temperature'] = np.nan\n",
    "#             df_capt_brut.loc[idx, 'Frequence_3_1'] = np.nan\n",
    "#         else:\n",
    "#             min_prominence = 1000\n",
    "#             peaks, peak_dict = find_peaks(df_ywf_3.Y1, prominence=(None, min_prominence), distance=100)\n",
    "#             peaks_max_1 = df_ywf_3.xf.to_numpy()[peaks[np.argsort(peak_dict['prominences'])[::-1]]][:1]\n",
    "\n",
    "#             if((peaks_max_1.size==0)):\n",
    "#                 df_capt_brut.loc[idx, 'Date_Heure'] = idx\n",
    "#                 df_capt_brut.loc[idx,'Temperature'] = df_jour.Temperature.mean()\n",
    "#                 df_capt_brut.loc[idx, 'Frequence_3_1'] = np.nan\n",
    "#             if((peaks_max_1.size==1)) :\n",
    "#                 df_capt_brut.loc[idx, 'Date_Heure'] = idx\n",
    "#                 df_capt_brut.loc[idx,'Temperature'] = df_jour.Temperature.mean()\n",
    "#                 df_capt_brut.loc[idx, 'Frequence_3_1'] = peaks_max_1[0]\n",
    "\n",
    "#         # Capteur 2\n",
    "\n",
    "#         # Ajout des valeurs de Fréquence_1_2\n",
    "#         if((df_ywf_1.Y2.iloc[0] == 0)):\n",
    "#             df_capt_brut.loc[idx, 'Date_Heure'] = idx\n",
    "#             df_capt_brut.loc[idx,'Temperature'] = np.nan\n",
    "#             df_capt_brut.loc[idx, 'Frequence_1_2'] = np.nan\n",
    "#         else:\n",
    "#             min_prominence = 1000\n",
    "#             peaks_2, peak_dict_2 = find_peaks(df_ywf_1.Y2, prominence=(None, min_prominence), distance=100)\n",
    "#             peaks_max_2 = df_ywf_1.xf.to_numpy()[peaks_2[np.argsort(peak_dict_2['prominences'])[::-1]]][:1]\n",
    "\n",
    "#             if((peaks_max_2.size==0)):\n",
    "#                 df_capt_brut.loc[idx, 'Date_Heure'] = idx\n",
    "#                 df_capt_brut.loc[idx,'Temperature'] = df_jour.Temperature.mean()\n",
    "#                 df_capt_brut.loc[idx, 'Frequence_1_2'] = np.nan\n",
    "#             if((peaks_max_2.size==1)) :\n",
    "#                 df_capt_brut.loc[idx, 'Date_Heure'] = idx\n",
    "#                 df_capt_brut.loc[idx,'Temperature'] = df_jour.Temperature.mean()\n",
    "#                 df_capt_brut.loc[idx, 'Frequence_1_2'] = peaks_max_2[0]\n",
    "#         # Ajout des valeurs de Fréquence_2_2\n",
    "#         if((df_ywf_2.Y2.iloc[0] == 0)):\n",
    "#             df_capt_brut.loc[idx, 'Date_Heure'] = idx\n",
    "#             df_capt_brut.loc[idx,'Temperature'] = np.nan\n",
    "#             df_capt_brut.loc[idx, 'Frequence_2_2'] = np.nan\n",
    "#         else:\n",
    "#             min_prominence = 1000\n",
    "#             peaks_2, peak_dict_2 = find_peaks(df_ywf_2.Y2, prominence=(None, min_prominence), distance=100)\n",
    "#             peaks_max_2 = df_ywf_2.xf.to_numpy()[peaks_2[np.argsort(peak_dict_2['prominences'])[::-1]]][:1]\n",
    "\n",
    "#             if((peaks_max_2.size==0)):\n",
    "#                 df_capt_brut.loc[idx, 'Date_Heure'] = idx\n",
    "#                 df_capt_brut.loc[idx,'Temperature'] = df_jour.Temperature.mean()\n",
    "#                 df_capt_brut.loc[idx, 'Frequence_2_2'] = np.nan\n",
    "#             if((peaks_max_2.size==1)) :\n",
    "#                 df_capt_brut.loc[idx, 'Date_Heure'] = idx\n",
    "#                 df_capt_brut.loc[idx,'Temperature'] = df_jour.Temperature.mean()\n",
    "#                 df_capt_brut.loc[idx, 'Frequence_2_2'] = peaks_max_2[0]\n",
    "#         # Ajout des valeurs de Fréquence_3_2\n",
    "#         if((df_ywf_3.Y2.iloc[0] == 0)):\n",
    "#             df_capt_brut.loc[idx, 'Date_Heure'] = idx\n",
    "#             df_capt_brut.loc[idx,'Temperature'] = np.nan\n",
    "#             df_capt_brut.loc[idx, 'Frequence_3_2'] = np.nan\n",
    "#         else:\n",
    "#             min_prominence = 1000\n",
    "#             peaks_2, peak_dict_2 = find_peaks(df_ywf_3.Y2, prominence=(None, min_prominence), distance=100)\n",
    "#             peaks_max_2 = df_ywf_3.xf.to_numpy()[peaks_2[np.argsort(peak_dict_2['prominences'])[::-1]]][:1]\n",
    "\n",
    "#             if((peaks_max_2.size==0)):\n",
    "#                 df_capt_brut.loc[idx, 'Date_Heure'] = idx\n",
    "#                 df_capt_brut.loc[idx,'Temperature'] = df_jour.Temperature.mean()\n",
    "#                 df_capt_brut.loc[idx, 'Frequence_3_2'] = np.nan\n",
    "#             if((peaks_max_2.size==1)) :\n",
    "#                 df_capt_brut.loc[idx, 'Date_Heure'] = idx\n",
    "#                 df_capt_brut.loc[idx,'Temperature'] = df_jour.Temperature.mean()\n",
    "#                 df_capt_brut.loc[idx, 'Frequence_3_2'] = peaks_max_2[0]            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80be4236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Changement des types\n",
    "# df_capt_brut['Date_Heure'] =  pd.to_datetime(df_capt_brut['Date_Heure'], format='%Y%M%D %H:%M:%S')\n",
    "# df_capt_brut['Temperature'] = df_capt_brut['Temperature'].astype(float)\n",
    "# df_capt_brut['Frequence_1_1'] = df_capt_brut['Frequence_1_1'].astype(float)\n",
    "# df_capt_brut['Frequence_2_1'] = df_capt_brut['Frequence_2_1'].astype(float)\n",
    "# df_capt_brut['Frequence_3_1'] = df_capt_brut['Frequence_3_1'].astype(float)\n",
    "# df_capt_brut['Frequence_1_2'] = df_capt_brut['Frequence_1_2'].astype(float)\n",
    "# df_capt_brut['Frequence_2_2'] = df_capt_brut['Frequence_2_2'].astype(float)\n",
    "# df_capt_brut['Frequence_3_2'] = df_capt_brut['Frequence_3_2'].astype(float)\n",
    "\n",
    "# # Création de la base de données en .txt et .csv \n",
    "# df_capt_brut.sort_values(by = 'Date_Heure').to_csv(r'Base_de_données_des_Fréquences/Base de données_Fréquences_Capteurs_1_&_2.txt', sep=\"\\t\", index=False)\n",
    "# df_capt_brut.sort_values(by = 'Date_Heure').to_csv(r'Base_de_données_des_Fréquences/Base de données_Fréquences_Capteurs_1_&_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e9ea32-ef01-4f78-a012-66b6642975e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%lsmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a190ed42-4297-4f51-8428-75d85d4de7a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
